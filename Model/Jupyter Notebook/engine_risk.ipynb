{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b87b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ff508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5689e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "WINDOW_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f68ccc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "SENSORS = [\n",
    "    's2', 's3', 's4', 's7', 's8', 's9',\n",
    "    's11', 's12', 's13', 's14', 's15', 's16'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547a224",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# LOAD CMAPSS DATA\n",
    "# -------------------------------\n",
    "def load_cmapss(path):\n",
    "    cols = ['engine_id', 'cycle', 'op1', 'op2', 'op3'] + \\\n",
    "           [f's{i}' for i in range(1, 22)]\n",
    "    return pd.read_csv(path, sep=' ', header=None, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7231cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_cmapss(\"train_FD001.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878a625",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# COMPUTE RUL\n",
    "# -------------------------------\n",
    "max_cycle = df.groupby('engine_id')['cycle'].max()\n",
    "df['RUL'] = df.apply(lambda r: max_cycle[r.engine_id] - r.cycle, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087234c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def rul_to_label(rul):\n",
    "    if rul > 50:\n",
    "        return 0\n",
    "    elif rul > 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ece6dc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "df['label'] = df['RUL'].apply(rul_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048765c9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# FEATURE EXTRACTION FOR TRAINING\n",
    "# -------------------------------\n",
    "def extract_training_features(df):\n",
    "    X, y = [], []\n",
    "\n",
    "    for eid in df.engine_id.unique():\n",
    "        eng = df[df.engine_id == eid].reset_index(drop=True)\n",
    "\n",
    "        for i in range(WINDOW_SIZE, len(eng)):\n",
    "            window = eng.iloc[i-WINDOW_SIZE:i]\n",
    "            features = []\n",
    "\n",
    "            for s in SENSORS:\n",
    "                v = window[s].values\n",
    "                features.extend([v.mean(), v.std(), v[-1] - v[0]])\n",
    "\n",
    "            X.append(features)\n",
    "            y.append(eng.loc[i, 'label'])\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = extract_training_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d276f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# TRAIN SCALER + MODEL\n",
    "# -------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e118e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f095d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f33edc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# CSV FEATURE EXTRACTOR (INFERENCE ONLY)\n",
    "# -------------------------------\n",
    "class CSVFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X must be a pandas DataFrame (raw CSV)\n",
    "        if len(X) < WINDOW_SIZE:\n",
    "            raise ValueError(\"CSV must contain at least 30 rows\")\n",
    "\n",
    "        window = X.iloc[-WINDOW_SIZE:]\n",
    "        features = []\n",
    "\n",
    "        for s in SENSORS:\n",
    "            if s not in X.columns:\n",
    "                raise ValueError(f\"Missing sensor: {s}\")\n",
    "            v = window[s].values\n",
    "            features.extend([v.mean(), v.std(), v[-1] - v[0]])\n",
    "\n",
    "        return np.array(features).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd0c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# SAVE SINGLE PIPELINE OBJECT\n",
    "# -------------------------------\n",
    "pipeline = {\n",
    "    \"feature_extractor\": CSVFeatureExtractor(),\n",
    "    \"scaler\": scaler,\n",
    "    \"model\": model,\n",
    "    \"label_map\": {\n",
    "        0: \"HEALTHY\",\n",
    "        1: \"MAINTENANCE\",\n",
    "        2: \"REPLACE\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353dfc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"engine_maintenance_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… Pipeline saved as engine_maintenance_pipeline.pkl\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
